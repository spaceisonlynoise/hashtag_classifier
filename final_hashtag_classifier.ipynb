{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kein undersampling sampling\n",
    "%store -r hash_texts\n",
    "%store -r hash_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######clean#######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from num2words import num2words\n",
    "#convert everything to lowercase\n",
    "hash_texts = [x.lower() for x in hash_texts]\n",
    "#exchange numbers with their string representation\n",
    "#make numbers to text\n",
    "temp = []\n",
    "without_num = []\n",
    "for post in hash_texts:\n",
    "    for word in post.split(\" \"):\n",
    "        if word.isdigit():\n",
    "            #print(word)\n",
    "            word = num2words(word, lang=\"de\")\n",
    "        temp.append(word)\n",
    "    without_num.append((' '.join(temp)))\n",
    "    temp = []\n",
    "hash_texts = without_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######feature extraction#########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#emoji feature\n",
    "emojis = [\"üò∑\",\"üò´\",\"ü§Æ\", \"üò£\", \"üòï\", \"üòç\", \"üòû\", \"üò¢\", \"üòÇ\", \"ü•∞\", \"üò≠\",\n",
    "          \"üò±\", \"üòí\", \"üòî\",\"üòï\", \"üòñ\", \"üò´\", \"üò§\", \"üò†\", \"üò°\", \"ü§¨\",\"üò™\"]\n",
    "from copy import deepcopy\n",
    "contains_emotional_emojis = deepcopy(hash_texts) #FEATURE\n",
    "#print(contains_emotional_emojis)\n",
    "for n, post in enumerate(contains_emotional_emojis):\n",
    "    for e in emojis:\n",
    "        if e in post:\n",
    "            #print(post)\n",
    "            contains_emotional_emojis[n] = [1]\n",
    "for n,i in enumerate(contains_emotional_emojis):\n",
    "    if not i == [1]:\n",
    "        contains_emotional_emojis[n] = [0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#without deleting stopwords\n",
    "#ngram feature matrices\n",
    "\n",
    "#unigram\n",
    "uni_vectorizer = CountVectorizer(ngram_range=(1,1))\n",
    "unigram_feature_vector = uni_vectorizer.fit_transform(hash_texts).toarray() \n",
    "\n",
    "#uni and bigram\n",
    "uni_bi_vectorizer = CountVectorizer(ngram_range=(1,2))\n",
    "unigram_bi_feature_vector = uni_bi_vectorizer.fit_transform(hash_texts).toarray() \n",
    "\n",
    "#bigram\n",
    "bi_vectorizer = CountVectorizer(ngram_range=(2,2))\n",
    "bigram_feature_vector = bi_vectorizer.fit_transform(hash_texts).toarray()\n",
    "\n",
    "\n",
    "#trigram\n",
    "tri_vectorizer = CountVectorizer(ngram_range=(3,3))\n",
    "trigram_feature_vector = tri_vectorizer.fit_transform(hash_texts).toarray() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tfidf vectorizer ohne stopwords zu l√∂schen\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf = tfidf_vectorizer.fit_transform(hash_texts).toarray() #feature matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "328\n"
     ]
    }
   ],
   "source": [
    "#numerical features\n",
    "#average length of post, average sentence length, average number of punctuation\n",
    "#punctuation weg lassen weil nicht wirklich aussagekr√§ftig\n",
    "\n",
    "\n",
    "import numpy\n",
    "import string\n",
    "from nltk import tokenize\n",
    "\n",
    "post_length = [] #feature vector\n",
    "counter = 0\n",
    "number_of_punct = [] #feature vector\n",
    "sentence_lengths = [] \n",
    "tokenized_posts = []\n",
    "for text in hash_texts:\n",
    "    post_length.append([len(text.split())])\n",
    "    tokenized_posts.append(tokenize.sent_tokenize(text))\n",
    "    for char in text:\n",
    "        if char in string.punctuation:\n",
    "            counter+=1\n",
    "    number_of_punct.append([counter])\n",
    "    counter = 0\n",
    "sent = []\n",
    "for post in tokenized_posts:\n",
    "    for sentence in post:\n",
    "        sent.append(len(sentence.split()))\n",
    "    sentence_lengths.append(sent)\n",
    "    sent = []\n",
    "#get average\n",
    "average_sent_len = [] #feature vector\n",
    "for post in sentence_lengths:\n",
    "    average_sent_len.append([sum(post)/len(post)])    \n",
    "print(len(sentence_lengths)) #why 2169?? need:1269 need one number, maybe the average sentence length?\n",
    "#print(average_sent_len)\n",
    "#print(sentence_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "328\n"
     ]
    }
   ],
   "source": [
    "#POS features\n",
    "import spacy\n",
    "nlp = spacy.load('de_core_news_md')\n",
    "\n",
    "#get POStags via spacy\n",
    "spacy_obj = []\n",
    "post_as_pos_tags = []\n",
    "as_pos = [] #this\n",
    "for text in hash_texts:\n",
    "    spacy_obj.append(nlp(text))\n",
    "for text in spacy_obj:\n",
    "    for token in text:\n",
    "        post_as_pos_tags.append(token.tag_)\n",
    "    as_pos.append(' '.join(post_as_pos_tags))\n",
    "    post_as_pos_tags = []\n",
    "\n",
    "#neue POS-features\n",
    "ADV_count = []\n",
    "PPER_count = []\n",
    "comma_count = []\n",
    "NE_count = []\n",
    "NN_count = []\n",
    "ADJD_count = []\n",
    "for post in as_pos:\n",
    "    ADV_count.append([post.count(\"ADV\")])\n",
    "    PPER_count.append([post.count(\"PPER\")])\n",
    "    comma_count.append([post.count(\"$,\")])\n",
    "    NE_count.append([post.count(\"NE\")])\n",
    "    NN_count.append([post.count(\"NN\")])\n",
    "    ADJD_count.append([post.count(\"ADJD\")])\n",
    "    \n",
    "print(len(ADJD_count))\n",
    "\n",
    "#EXPERIMENTS\n",
    "#get posts as sequence of pos tags\n",
    "#as_pos = sequence of pos tags\n",
    "#make sequences into count vectorizers\n",
    "pos_vec_uni = CountVectorizer(ngram_range=(1,1))\n",
    "pos_uni_count_vec = pos_vec_uni.fit_transform(as_pos).toarray() #uni feature vector\n",
    "pos_vec_bi = CountVectorizer(ngram_range=(2,2))\n",
    "pos_bi_count_vec = pos_vec_bi.fit_transform(as_pos).toarray() #bi feature vector\n",
    "#make theminto tfidf vectorizers\n",
    "tfidf_vectorizer_pos = TfidfVectorizer()\n",
    "tfidf_pos = tfidf_vectorizer_pos.fit_transform(as_pos) #tfidf pos feature matrix hat das iwelche benefits??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(328, 300)\n"
     ]
    }
   ],
   "source": [
    "#document vectors as features\n",
    "\n",
    "spacy_posts = []\n",
    "vector_posts = []\n",
    "temp_post = []\n",
    "for post in hash_texts:\n",
    "    spacy_posts.append(nlp(post))\n",
    "for post in spacy_posts:\n",
    "    for word in post:\n",
    "        temp_post.append(word.vector)\n",
    "    vector_posts.append(temp_post)\n",
    "    temp_post = []\n",
    "    \n",
    "mean_vector_posts = []\n",
    "for post_list in vector_posts:\n",
    "    #print(len(post))\n",
    "    mean_vector_posts.append([sum(post_list)/len(post_list)])\n",
    "    \n",
    "word_vector_feature = numpy.concatenate(mean_vector_posts, axis=0)\n",
    "print(word_vector_feature.shape)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "328\n",
      "from  (328, 55, 300)  to  (328, 16500)\n"
     ]
    }
   ],
   "source": [
    "#wordvectors as features\n",
    "\n",
    "#make all to numpy arrays\n",
    "np_posts = []\n",
    "for p in vector_posts:\n",
    "    np_posts.append(numpy.array(p))\n",
    "       \n",
    "#get matrix\n",
    "padded_arrays = []\n",
    "for p in np_posts:\n",
    "       padded_arrays.append(numpy.pad(p, ((0, (55 - p.shape[0])), (0, 0)), 'constant', constant_values=0))\n",
    "print(len(padded_arrays))\n",
    "\n",
    "\n",
    "\n",
    "np_pad_arr = numpy.array(padded_arrays)\n",
    "np_pad_arr.shape #shape (97, 48, 300)\n",
    "\n",
    "nodoc = numpy.reshape (np_pad_arr, (328, -1)) #FEATURE VECTOR FOR WORDVECTORS\n",
    "print(\"from \", np_pad_arr.shape, \" to \", nodoc.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################combine feature-vectors:##########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine feature-vectors:\n",
    "\n",
    "#uni-grams\n",
    "#unigram_feature_vector\n",
    "\n",
    "#bigrams\n",
    "#bigram_feature_vector\n",
    "\n",
    "#trigrams\n",
    "#trigram_feature_vector\n",
    "\n",
    "#unigrams and bigrams\n",
    "#unigram_bigram_feature_vector\n",
    "\n",
    "#tfidf\n",
    "\n",
    "#alle POS-features\n",
    "pos = numpy.append(ADV_count, comma_count, 1)\n",
    "pos = numpy.append(pos, NE_count, 1)\n",
    "pos = numpy.append(pos, NN_count, 1)\n",
    "pos = numpy.append(pos, ADJD_count, 1)\n",
    "pos = numpy.append(pos, PPER_count, 1)\n",
    "\n",
    "#numerical features\n",
    "#sentence_length\n",
    "post_sent = numpy.append(post_length, average_sent_len, 1)\n",
    "post_sent_punct = numpy.append(post_sent, number_of_punct, 1)\n",
    "\n",
    "#documents vectors\n",
    "#word_vector_feature\n",
    "\n",
    "#wordvectors\n",
    "#nodoc\n",
    "\n",
    "#emoji feature\n",
    "#contains_emotional_emojis\n",
    "\n",
    "# 3) uni-grams, bigrams, trigrams\n",
    "uni_bi_tri_feat_vec = numpy.append(unigram_feature_vector, bigram_feature_vector, 1)\n",
    "uni_bi_tri_feat_vec = numpy.append(uni_bi_tri_feat_vec,trigram_feature_vector, 1)\n",
    "\n",
    "# 4) tfidf and bigrams\n",
    "tfidf_bigram = numpy.append(tfidf, bigram_feature_vector, 1)\n",
    "\n",
    "# 5) unigrams and POS features\n",
    "uni_pos_new = numpy.append(unigram_feature_vector, pos, 1)\n",
    "\n",
    "# 6) unigrams and numerical features\n",
    "uni_num = numpy.append(unigram_feature_vector, post_sent_punct, 1)\n",
    "\n",
    "# 7) unigrams and POS tags and numerical features\n",
    "uni_num_pos = numpy.append(uni_num, pos, 1)\n",
    "\n",
    "# 8) Bigrams and POS\n",
    "bi_pos_new = numpy.append(bigram_feature_vector, pos, 1)\n",
    "\n",
    "# 9) bigrams and numerical features\n",
    "bi_num = numpy.append(bigram_feature_vector, post_sent_punct, 1)\n",
    "\n",
    "# 10) bigrams and POS tags and numerical features\n",
    "bi_num_pos = numpy.append(bi_num, pos, 1)\n",
    "\n",
    "# 11) tfidf and POS\n",
    "tfidf_pos_new = numpy.append(tfidf, pos, 1)\n",
    "\n",
    "# 12) tfidf and numerical features\n",
    "tfidf_num = numpy.append(tfidf, post_sent_punct, 1)\n",
    "\n",
    "# 13) tfidf and POS tags and numerical features\n",
    "tfidf_num_pos = numpy.append(tfidf_num, pos, 1)\n",
    "\n",
    "# 14) wordvec and POS\n",
    "wordvec_pos = numpy.append(nodoc, pos, 1)\n",
    "\n",
    "# 15) wordvec and numerical features\n",
    "wordvec_num = numpy.append(nodoc, post_sent_punct, 1)\n",
    "\n",
    "# 16) wordvec and POS tags and numerical features\n",
    "wordvec_num_pos = numpy.append(wordvec_num, pos, 1)\n",
    "\n",
    "# 17) docvec and POS\n",
    "docvec_pos = numpy.append(word_vector_feature, pos, 1)\n",
    "\n",
    "# 18) docvec and numerical features\n",
    "docvec_num = numpy.append(word_vector_feature, post_sent_punct, 1)\n",
    "\n",
    "# 19) docvec and POS tags and numerical features\n",
    "docvec_num_pos = numpy.append(docvec_num, pos, 1)\n",
    "\n",
    "\n",
    "# 20)POS and numerical features\n",
    "pos_post_sent_len = numpy.append(pos, post_sent, 1)\n",
    "pos_num = numpy.append(post_sent_punct, pos, 1)\n",
    "\n",
    "# 21) alle\n",
    "all_features = numpy.append(unigram_feature_vector, bigram_feature_vector, 1)\n",
    "all_features = numpy.append(all_features, trigram_feature_vector , 1)\n",
    "all_features = numpy.append(all_features, tfidf, 1)\n",
    "all_features = numpy.append(all_features,post_sent_punct, 1)\n",
    "all_features = numpy.append(all_features, pos, 1)\n",
    "all_features = numpy.append(all_features,nodoc, 1)\n",
    "all_features = numpy.append(all_features,word_vector_feature, 1)\n",
    "all_features = numpy.append(all_features,contains_emotional_emojis, 1)\n",
    "\n",
    "# 22) hash unigram\n",
    "emot_uni = numpy.append(unigram_feature_vector, contains_emotional_emojis, 1)\n",
    "# 23) hash bigram\n",
    "emot_bi = numpy.append(bigram_feature_vector,contains_emotional_emojis, 1)\n",
    "# 24) hash tfidf\n",
    "emot_tfidf = numpy.append(tfidf,contains_emotional_emojis, 1)\n",
    "# 25) hash wordvectors\n",
    "emot_wordvec = numpy.append(nodoc,contains_emotional_emojis, 1)\n",
    "# 26) hash docvecs\n",
    "emot_docvec = numpy.append(word_vector_feature,contains_emotional_emojis, 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########train and test######################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "######logistic regression########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import cross_val_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores: [0.72727273 0.81818182 0.72727273 0.90909091 0.66666667 0.81818182\n",
      " 0.6969697  0.84848485 0.65625    0.78125   ]\n",
      "Accuracy: 0.765 (0.079)\n"
     ]
    }
   ],
   "source": [
    "X = unigram_feature_vector#data\n",
    "y = hash_labels#target\n",
    "\n",
    "kf = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "\n",
    "# create model\n",
    "model = LogisticRegression(class_weight='balanced')\n",
    "\n",
    "# evaluate model\n",
    "scores = cross_val_score(model, X, y, scoring='accuracy', cv=kf, n_jobs=-1)\n",
    "print(\"scores:\", scores)\n",
    "\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores: [0.57575758 0.78787879 0.75757576 0.81818182 0.75757576 0.78787879\n",
      " 0.75757576 0.72727273 0.71875    0.71875   ]\n",
      "Accuracy: 0.741 (0.063)\n"
     ]
    }
   ],
   "source": [
    "X = bigram_feature_vector#data\n",
    "y = hash_labels#target\n",
    "\n",
    "kf = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "\n",
    "# create model\n",
    "model = LogisticRegression(class_weight='balanced')\n",
    "\n",
    "# evaluate model\n",
    "scores = cross_val_score(model, X, y, scoring='accuracy', cv=kf, n_jobs=-1)\n",
    "print(\"scores:\", scores)\n",
    "\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores: [0.54545455 0.78787879 0.75757576 0.78787879 0.6969697  0.72727273\n",
      " 0.75757576 0.6969697  0.65625    0.65625   ]\n",
      "Accuracy: 0.707 (0.071)\n"
     ]
    }
   ],
   "source": [
    "X = trigram_feature_vector#data\n",
    "y = hash_labels#target\n",
    "\n",
    "kf = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "\n",
    "# create model\n",
    "model = LogisticRegression(class_weight='balanced')\n",
    "\n",
    "# evaluate model\n",
    "scores = cross_val_score(model, X, y, scoring='accuracy', cv=kf, n_jobs=-1)\n",
    "print(\"scores:\", scores)\n",
    "\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores: [0.72727273 0.87878788 0.78787879 0.90909091 0.72727273 0.78787879\n",
      " 0.81818182 0.90909091 0.6875     0.8125    ]\n",
      "Accuracy: 0.805 (0.073)\n"
     ]
    }
   ],
   "source": [
    "X = tfidf#data\n",
    "y = hash_labels#target\n",
    "\n",
    "kf = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "\n",
    "# create model\n",
    "model = LogisticRegression(class_weight='balanced')\n",
    "\n",
    "# evaluate model\n",
    "scores = cross_val_score(model, X, y, scoring='accuracy', cv=kf, n_jobs=-1)\n",
    "print(\"scores:\", scores)\n",
    "\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores: [0.57575758 0.75757576 0.6969697  0.6969697  0.54545455 0.6969697\n",
      " 0.54545455 0.75757576 0.53125    0.53125   ]\n",
      "Accuracy: 0.634 (0.091)\n"
     ]
    }
   ],
   "source": [
    "X = post_sent_punct#data\n",
    "y = hash_labels#target\n",
    "\n",
    "kf = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "\n",
    "# create model\n",
    "model = LogisticRegression(class_weight='balanced')\n",
    "\n",
    "# evaluate model\n",
    "scores = cross_val_score(model, X, y, scoring='accuracy', cv=kf, n_jobs=-1)\n",
    "print(\"scores:\", scores)\n",
    "\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores: [0.54545455 0.75757576 0.60606061 0.66666667 0.57575758 0.72727273\n",
      " 0.6969697  0.66666667 0.53125    0.65625   ]\n",
      "Accuracy: 0.643 (0.072)\n"
     ]
    }
   ],
   "source": [
    "X = pos#data\n",
    "y = hash_labels#target\n",
    "\n",
    "kf = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "\n",
    "# create model\n",
    "model = LogisticRegression(class_weight='balanced')\n",
    "\n",
    "# evaluate model\n",
    "scores = cross_val_score(model, X, y, scoring='accuracy', cv=kf, n_jobs=-1)\n",
    "print(\"scores:\", scores)\n",
    "\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores: [0.63636364 0.78787879 0.78787879 0.72727273 0.6969697  0.72727273\n",
      " 0.66666667 0.78787879 0.8125     0.71875   ]\n",
      "Accuracy: 0.735 (0.055)\n"
     ]
    }
   ],
   "source": [
    "X = nodoc#data\n",
    "y = hash_labels#target\n",
    "\n",
    "kf = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "\n",
    "# create model\n",
    "model = LogisticRegression(class_weight='balanced')\n",
    "\n",
    "# evaluate model\n",
    "scores = cross_val_score(model, X, y, scoring='accuracy', cv=kf, n_jobs=-1)\n",
    "print(\"scores:\", scores)\n",
    "\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores: [0.6969697  0.90909091 0.78787879 0.87878788 0.6969697  0.81818182\n",
      " 0.84848485 0.78787879 0.8125     0.8125    ]\n",
      "Accuracy: 0.805 (0.065)\n"
     ]
    }
   ],
   "source": [
    "X = word_vector_feature#data\n",
    "y = hash_labels#target\n",
    "\n",
    "kf = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "\n",
    "# create model\n",
    "model = LogisticRegression(class_weight='balanced')\n",
    "\n",
    "# evaluate model\n",
    "scores = cross_val_score(model, X, y, scoring='accuracy', cv=kf, n_jobs=-1)\n",
    "print(\"scores:\", scores)\n",
    "\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "##combinations##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores: [0.66666667 0.84848485 0.78787879 0.84848485 0.72727273 0.81818182\n",
      " 0.72727273 0.84848485 0.71875    0.8125    ]\n",
      "Accuracy: 0.780 (0.062)\n"
     ]
    }
   ],
   "source": [
    "#2\n",
    "X = unigram_bi_feature_vector#data\n",
    "y = hash_labels#target\n",
    "\n",
    "kf = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "\n",
    "# create model\n",
    "model = LogisticRegression(class_weight='balanced')\n",
    "\n",
    "# evaluate model\n",
    "scores = cross_val_score(model, X, y, scoring='accuracy', cv=kf, n_jobs=-1)\n",
    "print(\"scores:\", scores)\n",
    "\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores: [0.66666667 0.84848485 0.78787879 0.84848485 0.72727273 0.84848485\n",
      " 0.72727273 0.84848485 0.71875    0.8125    ]\n",
      "Accuracy: 0.783 (0.065)\n"
     ]
    }
   ],
   "source": [
    "#3\n",
    "X = uni_bi_tri_feat_vec#data\n",
    "y = hash_labels#target\n",
    "\n",
    "kf = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "\n",
    "# create model\n",
    "model = LogisticRegression(class_weight='balanced')\n",
    "\n",
    "# evaluate model\n",
    "scores = cross_val_score(model, X, y, scoring='accuracy', cv=kf, n_jobs=-1)\n",
    "print(\"scores:\", scores)\n",
    "\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores: [0.51515152 0.81818182 0.78787879 0.84848485 0.72727273 0.78787879\n",
      " 0.75757576 0.72727273 0.71875    0.71875   ]\n",
      "Accuracy: 0.741 (0.086)\n"
     ]
    }
   ],
   "source": [
    "#4\n",
    "X = tfidf_bigram#data\n",
    "y = hash_labels#target\n",
    "\n",
    "kf = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "\n",
    "# create model\n",
    "model = LogisticRegression(class_weight='balanced')\n",
    "\n",
    "# evaluate model\n",
    "scores = cross_val_score(model, X, y, scoring='accuracy', cv=kf, n_jobs=-1)\n",
    "print(\"scores:\", scores)\n",
    "\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores: [0.72727273 0.84848485 0.75757576 0.93939394 0.72727273 0.78787879\n",
      " 0.75757576 0.81818182 0.6875     0.8125    ]\n",
      "Accuracy: 0.786 (0.069)\n"
     ]
    }
   ],
   "source": [
    "#5\n",
    "X = uni_pos_new#data\n",
    "y = hash_labels#target\n",
    "\n",
    "kf = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "\n",
    "# create model\n",
    "model = LogisticRegression(class_weight='balanced')\n",
    "\n",
    "# evaluate model\n",
    "scores = cross_val_score(model, X, y, scoring='accuracy', cv=kf, n_jobs=-1)\n",
    "print(\"scores:\", scores)\n",
    "\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores: [0.6969697  0.84848485 0.78787879 0.93939394 0.6969697  0.78787879\n",
      " 0.78787879 0.87878788 0.65625    0.78125   ]\n",
      "Accuracy: 0.786 (0.083)\n"
     ]
    }
   ],
   "source": [
    "#6\n",
    "X = uni_num#data\n",
    "y = hash_labels#target\n",
    "\n",
    "kf = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "\n",
    "# create model\n",
    "model = LogisticRegression(class_weight='balanced')\n",
    "\n",
    "# evaluate model\n",
    "scores = cross_val_score(model, X, y, scoring='accuracy', cv=kf, n_jobs=-1)\n",
    "print(\"scores:\", scores)\n",
    "\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores: [0.72727273 0.87878788 0.72727273 0.93939394 0.75757576 0.78787879\n",
      " 0.84848485 0.87878788 0.6875     0.8125    ]\n",
      "Accuracy: 0.805 (0.077)\n"
     ]
    }
   ],
   "source": [
    "#7\n",
    "X = uni_num_pos#data\n",
    "y = hash_labels#target\n",
    "\n",
    "kf = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "\n",
    "# create model\n",
    "model = LogisticRegression(class_weight='balanced')\n",
    "\n",
    "# evaluate model\n",
    "scores = cross_val_score(model, X, y, scoring='accuracy', cv=kf, n_jobs=-1)\n",
    "print(\"scores:\", scores)\n",
    "\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores: [0.60606061 0.81818182 0.87878788 0.75757576 0.75757576 0.75757576\n",
      " 0.75757576 0.78787879 0.6875     0.78125   ]\n",
      "Accuracy: 0.759 (0.069)\n"
     ]
    }
   ],
   "source": [
    "#8\n",
    "X = bi_pos_new#data\n",
    "y = hash_labels#target\n",
    "\n",
    "kf = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "\n",
    "# create model\n",
    "model = LogisticRegression(class_weight='balanced')\n",
    "\n",
    "# evaluate model\n",
    "scores = cross_val_score(model, X, y, scoring='accuracy', cv=kf, n_jobs=-1)\n",
    "print(\"scores:\", scores)\n",
    "\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores: [0.54545455 0.78787879 0.78787879 0.81818182 0.72727273 0.78787879\n",
      " 0.78787879 0.75757576 0.6875     0.6875    ]\n",
      "Accuracy: 0.738 (0.077)\n"
     ]
    }
   ],
   "source": [
    "#9\n",
    "X = bi_num#data\n",
    "y = hash_labels#target\n",
    "\n",
    "kf = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "\n",
    "# create model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# evaluate model\n",
    "scores = cross_val_score(model, X, y, scoring='accuracy', cv=kf, n_jobs=-1)\n",
    "print(\"scores:\", scores)\n",
    "\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores: [0.63636364 0.90909091 0.72727273 0.78787879 0.75757576 0.78787879\n",
      " 0.75757576 0.75757576 0.65625    0.75      ]\n",
      "Accuracy: 0.753 (0.071)\n"
     ]
    }
   ],
   "source": [
    "#10\n",
    "X = bi_num_pos#data\n",
    "y = hash_labels#target\n",
    "\n",
    "kf = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "\n",
    "# create model\n",
    "model = LogisticRegression(class_weight='balanced')\n",
    "\n",
    "# evaluate model\n",
    "scores = cross_val_score(model, X, y, scoring='accuracy', cv=kf, n_jobs=-1)\n",
    "print(\"scores:\", scores)\n",
    "\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores: [0.60606061 0.90909091 0.78787879 0.75757576 0.72727273 0.81818182\n",
      " 0.72727273 0.6969697  0.5625     0.8125    ]\n",
      "Accuracy: 0.741 (0.097)\n"
     ]
    }
   ],
   "source": [
    "#11\n",
    "X = tfidf_pos_new#data\n",
    "y = hash_labels#target\n",
    "\n",
    "kf = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "\n",
    "# create model\n",
    "model = LogisticRegression(class_weight='balanced')\n",
    "\n",
    "# evaluate model\n",
    "scores = cross_val_score(model, X, y, scoring='accuracy', cv=kf, n_jobs=-1)\n",
    "print(\"scores:\", scores)\n",
    "\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores: [0.60606061 0.84848485 0.78787879 0.75757576 0.72727273 0.72727273\n",
      " 0.78787879 0.84848485 0.625      0.6875    ]\n",
      "Accuracy: 0.740 (0.079)\n"
     ]
    }
   ],
   "source": [
    "#12\n",
    "X = tfidf_num#data\n",
    "y = hash_labels#target\n",
    "\n",
    "kf = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "\n",
    "# create model\n",
    "model = LogisticRegression(class_weight='balanced')\n",
    "\n",
    "# evaluate model\n",
    "scores = cross_val_score(model, X, y, scoring='accuracy', cv=kf, n_jobs=-1)\n",
    "print(\"scores:\", scores)\n",
    "\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores: [0.63636364 0.93939394 0.75757576 0.75757576 0.75757576 0.75757576\n",
      " 0.75757576 0.78787879 0.6875     0.75      ]\n",
      "Accuracy: 0.759 (0.073)\n"
     ]
    }
   ],
   "source": [
    "#13\n",
    "X = tfidf_num_pos#data\n",
    "y = hash_labels#target\n",
    "\n",
    "kf = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "\n",
    "# create model\n",
    "model = LogisticRegression(class_weight='balanced')\n",
    "\n",
    "# evaluate model\n",
    "scores = cross_val_score(model, X, y, scoring='accuracy', cv=kf, n_jobs=-1)\n",
    "print(\"scores:\", scores)\n",
    "\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores: [0.66666667 0.78787879 0.75757576 0.72727273 0.6969697  0.72727273\n",
      " 0.66666667 0.78787879 0.8125     0.71875   ]\n",
      "Accuracy: 0.735 (0.048)\n"
     ]
    }
   ],
   "source": [
    "#14\n",
    "X = wordvec_pos#data\n",
    "y =hash_labels#target\n",
    "\n",
    "kf = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "\n",
    "# create model\n",
    "model = LogisticRegression(class_weight='balanced')\n",
    "\n",
    "# evaluate model\n",
    "scores = cross_val_score(model, X, y, scoring='accuracy', cv=kf, n_jobs=-1)\n",
    "print(\"scores:\", scores)\n",
    "\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores: [0.66666667 0.78787879 0.75757576 0.72727273 0.72727273 0.72727273\n",
      " 0.6969697  0.78787879 0.84375    0.71875   ]\n",
      "Accuracy: 0.744 (0.049)\n"
     ]
    }
   ],
   "source": [
    "#15\n",
    "X = wordvec_num#data\n",
    "y = hash_labels#target\n",
    "\n",
    "kf = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "\n",
    "# create model\n",
    "model = LogisticRegression(class_weight='balanced')\n",
    "\n",
    "# evaluate model\n",
    "scores = cross_val_score(model, X, y, scoring='accuracy', cv=kf, n_jobs=-1)\n",
    "print(\"scores:\", scores)\n",
    "\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores: [0.66666667 0.78787879 0.75757576 0.72727273 0.72727273 0.72727273\n",
      " 0.6969697  0.78787879 0.84375    0.71875   ]\n",
      "Accuracy: 0.744 (0.049)\n"
     ]
    }
   ],
   "source": [
    "#16\n",
    "X = wordvec_num_pos#data\n",
    "y = hash_labels#target\n",
    "\n",
    "kf = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "\n",
    "# create model\n",
    "model = LogisticRegression(class_weight='balanced')\n",
    "\n",
    "# evaluate model\n",
    "scores = cross_val_score(model, X, y, scoring='accuracy', cv=kf, n_jobs=-1)\n",
    "print(\"scores:\", scores)\n",
    "\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores: [0.75757576 0.93939394 0.78787879 0.84848485 0.6969697  0.81818182\n",
      " 0.84848485 0.75757576 0.875      0.78125   ]\n",
      "Accuracy: 0.811 (0.066)\n"
     ]
    }
   ],
   "source": [
    "#17\n",
    "X = docvec_num#data\n",
    "y = hash_labels#target\n",
    "\n",
    "kf = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "\n",
    "# create model\n",
    "model = LogisticRegression(class_weight='balanced')\n",
    "\n",
    "# evaluate model\n",
    "scores = cross_val_score(model, X, y, scoring='accuracy', cv=kf, n_jobs=-1)\n",
    "print(\"scores:\", scores)\n",
    "\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores: [0.78787879 0.90909091 0.78787879 0.87878788 0.6969697  0.84848485\n",
      " 0.84848485 0.78787879 0.8125     0.8125    ]\n",
      "Accuracy: 0.817 (0.056)\n"
     ]
    }
   ],
   "source": [
    "#18\n",
    "X = docvec_pos#data\n",
    "y = hash_labels#target\n",
    "\n",
    "kf = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "\n",
    "# create model\n",
    "model = LogisticRegression(class_weight='balanced')\n",
    "\n",
    "# evaluate model\n",
    "scores = cross_val_score(model, X, y, scoring='accuracy', cv=kf, n_jobs=-1)\n",
    "print(\"scores:\", scores)\n",
    "\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores: [0.75757576 0.93939394 0.78787879 0.87878788 0.6969697  0.81818182\n",
      " 0.84848485 0.75757576 0.875      0.78125   ]\n",
      "Accuracy: 0.814 (0.068)\n"
     ]
    }
   ],
   "source": [
    "#19\n",
    "X = docvec_num_pos#data\n",
    "y = hash_labels#target\n",
    "\n",
    "kf = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "\n",
    "# create model\n",
    "model = LogisticRegression(class_weight='balanced')\n",
    "\n",
    "# evaluate model\n",
    "scores = cross_val_score(model, X, y, scoring='accuracy', cv=kf, n_jobs=-1)\n",
    "print(\"scores:\", scores)\n",
    "\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores: [0.57575758 0.84848485 0.6969697  0.6969697  0.66666667 0.78787879\n",
      " 0.6969697  0.6969697  0.625      0.625     ]\n",
      "Accuracy: 0.692 (0.075)\n"
     ]
    }
   ],
   "source": [
    "#20\n",
    "X = pos_num#data\n",
    "y = hash_labels#target\n",
    "\n",
    "kf = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "\n",
    "# create model\n",
    "model = LogisticRegression(class_weight='balanced')\n",
    "\n",
    "# evaluate model\n",
    "scores = cross_val_score(model, X, y, scoring='accuracy', cv=kf, n_jobs=-1)\n",
    "print(\"scores:\", scores)\n",
    "\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores: [0.66666667 0.81818182 0.75757576 0.72727273 0.75757576 0.72727273\n",
      " 0.6969697  0.78787879 0.84375    0.71875   ]\n",
      "Accuracy: 0.750 (0.052)\n"
     ]
    }
   ],
   "source": [
    "#21\n",
    "X = all_features#data\n",
    "y = hash_labels#target\n",
    "\n",
    "kf = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "\n",
    "# create model\n",
    "model = LogisticRegression(class_weight='balanced')\n",
    "\n",
    "# evaluate model\n",
    "scores = cross_val_score(model, X, y, scoring='accuracy', cv=kf, n_jobs=-1)\n",
    "print(\"scores:\", scores)\n",
    "\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores: [0.72727273 0.81818182 0.75757576 0.90909091 0.66666667 0.81818182\n",
      " 0.6969697  0.84848485 0.6875     0.78125   ]\n",
      "Accuracy: 0.771 (0.074)\n"
     ]
    }
   ],
   "source": [
    "#22\n",
    "X = emot_uni#data\n",
    "y = hash_labels#target\n",
    "\n",
    "kf = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "\n",
    "# create model\n",
    "model = LogisticRegression(class_weight='balanced')\n",
    "\n",
    "# evaluate model\n",
    "scores = cross_val_score(model, X, y, scoring='accuracy', cv=kf, n_jobs=-1)\n",
    "print(\"scores:\", scores)\n",
    "\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores: [0.54545455 0.78787879 0.75757576 0.81818182 0.75757576 0.81818182\n",
      " 0.75757576 0.75757576 0.75       0.71875   ]\n",
      "Accuracy: 0.747 (0.073)\n"
     ]
    }
   ],
   "source": [
    "#23\n",
    "X = emot_bi#data\n",
    "y = hash_labels#target\n",
    "\n",
    "kf = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "\n",
    "# create model\n",
    "model = LogisticRegression(class_weight='balanced')\n",
    "\n",
    "# evaluate model\n",
    "scores = cross_val_score(model, X, y, scoring='accuracy', cv=kf, n_jobs=-1)\n",
    "print(\"scores:\", scores)\n",
    "\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores: [0.63636364 0.87878788 0.78787879 0.90909091 0.63636364 0.84848485\n",
      " 0.75757576 0.90909091 0.71875    0.8125    ]\n",
      "Accuracy: 0.789 (0.097)\n"
     ]
    }
   ],
   "source": [
    "#24\n",
    "X = emot_tfidf#data\n",
    "y = hash_labels#target\n",
    "\n",
    "kf = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "\n",
    "# create model\n",
    "model = LogisticRegression(class_weight='balanced')\n",
    "\n",
    "# evaluate model\n",
    "scores = cross_val_score(model, X, y, scoring='accuracy', cv=kf, n_jobs=-1)\n",
    "print(\"scores:\", scores)\n",
    "\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores: [0.63636364 0.78787879 0.78787879 0.72727273 0.6969697  0.72727273\n",
      " 0.66666667 0.78787879 0.8125     0.71875   ]\n",
      "Accuracy: 0.735 (0.055)\n"
     ]
    }
   ],
   "source": [
    "#25\n",
    "X = emot_wordvec#data\n",
    "y = hash_labels#target\n",
    "\n",
    "kf = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "\n",
    "# create model\n",
    "model = LogisticRegression(class_weight='balanced')\n",
    "\n",
    "# evaluate model\n",
    "scores = cross_val_score(model, X, y, scoring='accuracy', cv=kf, n_jobs=-1)\n",
    "print(\"scores:\", scores)\n",
    "\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores: [0.6969697  0.90909091 0.78787879 0.87878788 0.6969697  0.81818182\n",
      " 0.84848485 0.78787879 0.8125     0.8125    ]\n",
      "Accuracy: 0.805 (0.065)\n"
     ]
    }
   ],
   "source": [
    "#26\n",
    "X = emot_docvec#data\n",
    "y = hash_labels#target\n",
    "\n",
    "kf = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "\n",
    "# create model\n",
    "model = LogisticRegression(class_weight='balanced')\n",
    "\n",
    "# evaluate model\n",
    "scores = cross_val_score(model, X, y, scoring='accuracy', cv=kf, n_jobs=-1)\n",
    "print(\"scores:\", scores)\n",
    "\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores: [0.51515152 0.78787879 0.75757576 0.84848485 0.6969697  0.75757576\n",
      " 0.75757576 0.78787879 0.6875     0.65625   ]\n",
      "Accuracy: 0.725 (0.088)\n"
     ]
    }
   ],
   "source": [
    "#26\n",
    "X = contains_emotional_emojis#data\n",
    "y = hash_labels#target\n",
    "\n",
    "kf = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "\n",
    "# create model\n",
    "model = LogisticRegression(class_weight='balanced')\n",
    "\n",
    "# evaluate model\n",
    "scores = cross_val_score(model, X, y, scoring='accuracy', cv=kf, n_jobs=-1)\n",
    "print(\"scores:\", scores)\n",
    "\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############naive bayes##############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores: [0.63636364 0.72727273 0.75757576 0.72727273 0.66666667 0.72727273\n",
      " 0.63636364 0.72727273 0.71875    0.75      ]\n",
      "Accuracy: 0.707 (0.042)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X = unigram_feature_vector#data\n",
    "y = hash_labels#target\n",
    "\n",
    "kf = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "\n",
    "# create model\n",
    "model = GaussianNB()\n",
    "\n",
    "# evaluate model\n",
    "scores = cross_val_score(model, X, y, scoring='accuracy', cv=kf, n_jobs=-1)\n",
    "print(\"scores:\", scores)\n",
    "\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores: [0.75757576 0.72727273 0.66666667 0.72727273 0.75757576 0.72727273\n",
      " 0.75757576 0.72727273 0.78125    0.6875    ]\n",
      "Accuracy: 0.732 (0.033)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X = bigram_feature_vector#data\n",
    "y = hash_labels#target\n",
    "\n",
    "kf = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "\n",
    "# create model\n",
    "model = GaussianNB()\n",
    "\n",
    "# evaluate model\n",
    "scores = cross_val_score(model, X, y, scoring='accuracy', cv=kf, n_jobs=-1)\n",
    "print(\"scores:\", scores)\n",
    "\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores: [0.57575758 0.54545455 0.42424242 0.33333333 0.51515152 0.45454545\n",
      " 0.60606061 0.45454545 0.5        0.625     ]\n",
      "Accuracy: 0.503 (0.085)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X = trigram_feature_vector#data\n",
    "y = hash_labels#target\n",
    "\n",
    "kf = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "\n",
    "# create model\n",
    "model = GaussianNB()\n",
    "\n",
    "# evaluate model\n",
    "scores = cross_val_score(model, X, y, scoring='accuracy', cv=kf, n_jobs=-1)\n",
    "print(\"scores:\", scores)\n",
    "\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores: [0.63636364 0.72727273 0.78787879 0.72727273 0.66666667 0.72727273\n",
      " 0.66666667 0.72727273 0.75       0.75      ]\n",
      "Accuracy: 0.717 (0.044)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X = tfidf#data\n",
    "y = hash_labels#target\n",
    "\n",
    "kf = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "\n",
    "# create model\n",
    "model = GaussianNB()\n",
    "\n",
    "# evaluate model\n",
    "scores = cross_val_score(model, X, y, scoring='accuracy', cv=kf, n_jobs=-1)\n",
    "print(\"scores:\", scores)\n",
    "\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores: [0.51515152 0.78787879 0.72727273 0.72727273 0.6969697  0.72727273\n",
      " 0.78787879 0.78787879 0.71875    0.625     ]\n",
      "Accuracy: 0.710 (0.080)\n"
     ]
    }
   ],
   "source": [
    "X = post_sent_punct#data\n",
    "y = hash_labels#target\n",
    "\n",
    "kf = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "\n",
    "# create model\n",
    "model = GaussianNB()\n",
    "\n",
    "# evaluate model\n",
    "scores = cross_val_score(model, X, y, scoring='accuracy', cv=kf, n_jobs=-1)\n",
    "print(\"scores:\", scores)\n",
    "\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores: [0.51515152 0.72727273 0.78787879 0.75757576 0.6969697  0.84848485\n",
      " 0.6969697  0.6969697  0.5625     0.71875   ]\n",
      "Accuracy: 0.701 (0.093)\n"
     ]
    }
   ],
   "source": [
    "X = pos#data\n",
    "y = hash_labels#target\n",
    "\n",
    "kf = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "\n",
    "# create model\n",
    "model = GaussianNB()\n",
    "\n",
    "# evaluate model\n",
    "scores = cross_val_score(model, X, y, scoring='accuracy', cv=kf, n_jobs=-1)\n",
    "print(\"scores:\", scores)\n",
    "\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores: [0.48484848 0.21212121 0.24242424 0.24242424 0.33333333 0.24242424\n",
      " 0.24242424 0.3030303  0.34375    0.34375   ]\n",
      "Accuracy: 0.299 (0.078)\n"
     ]
    }
   ],
   "source": [
    "#WTF?\n",
    "X = nodoc#data\n",
    "y = hash_labels#target\n",
    "\n",
    "kf = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "\n",
    "# create model\n",
    "model = GaussianNB()\n",
    "\n",
    "# evaluate model\n",
    "scores = cross_val_score(model, X, y, scoring='accuracy', cv=kf, n_jobs=-1)\n",
    "print(\"scores:\", scores)\n",
    "\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores: [0.81818182 0.78787879 0.87878788 0.84848485 0.81818182 0.63636364\n",
      " 0.75757576 0.90909091 0.71875    0.78125   ]\n",
      "Accuracy: 0.795 (0.075)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X = word_vector_feature#data\n",
    "y = hash_labels#target\n",
    "\n",
    "kf = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "\n",
    "# create model\n",
    "model = GaussianNB()\n",
    "\n",
    "# evaluate model\n",
    "scores = cross_val_score(model, X, y, scoring='accuracy', cv=kf, n_jobs=-1)\n",
    "print(\"scores:\", scores)\n",
    "\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "##combinations##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores: [0.78787879 0.81818182 0.78787879 0.81818182 0.78787879 0.81818182\n",
      " 0.81818182 0.72727273 0.6875     0.71875   ]\n",
      "Accuracy: 0.777 (0.046)\n"
     ]
    }
   ],
   "source": [
    "#2\n",
    "X = unigram_bi_feature_vector#data\n",
    "y = hash_labels#target\n",
    "\n",
    "kf = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "\n",
    "model = GaussianNB()\n",
    "\n",
    "# evaluate model\n",
    "scores = cross_val_score(model, X, y, scoring='accuracy', cv=kf, n_jobs=-1)\n",
    "print(\"scores:\", scores)\n",
    "\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores: [0.78787879 0.81818182 0.81818182 0.81818182 0.78787879 0.81818182\n",
      " 0.81818182 0.72727273 0.65625    0.71875   ]\n",
      "Accuracy: 0.777 (0.054)\n"
     ]
    }
   ],
   "source": [
    "#3\n",
    "X = uni_bi_tri_feat_vec#data\n",
    "y = hash_labels#target\n",
    "\n",
    "kf = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "\n",
    "# create model\n",
    "model = GaussianNB()\n",
    "\n",
    "# evaluate model\n",
    "scores = cross_val_score(model, X, y, scoring='accuracy', cv=kf, n_jobs=-1)\n",
    "print(\"scores:\", scores)\n",
    "\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores: [0.75757576 0.81818182 0.81818182 0.75757576 0.87878788 0.81818182\n",
      " 0.81818182 0.78787879 0.71875    0.71875   ]\n",
      "Accuracy: 0.789 (0.048)\n"
     ]
    }
   ],
   "source": [
    "#4\n",
    "X = tfidf_bigram#data\n",
    "y = hash_labels#target\n",
    "\n",
    "kf = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "\n",
    "# create model\n",
    "model = GaussianNB()\n",
    "\n",
    "# evaluate model\n",
    "scores = cross_val_score(model, X, y, scoring='accuracy', cv=kf, n_jobs=-1)\n",
    "print(\"scores:\", scores)\n",
    "\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores: [0.63636364 0.72727273 0.75757576 0.72727273 0.66666667 0.72727273\n",
      " 0.63636364 0.72727273 0.71875    0.75      ]\n",
      "Accuracy: 0.707 (0.042)\n"
     ]
    }
   ],
   "source": [
    "#5\n",
    "X = uni_pos_new#data\n",
    "y = hash_labels#target\n",
    "\n",
    "kf = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "\n",
    "# create model\n",
    "model = GaussianNB()\n",
    "\n",
    "# evaluate model\n",
    "scores = cross_val_score(model, X, y, scoring='accuracy', cv=kf, n_jobs=-1)\n",
    "print(\"scores:\", scores)\n",
    "\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores: [0.63636364 0.72727273 0.75757576 0.72727273 0.66666667 0.72727273\n",
      " 0.63636364 0.72727273 0.71875    0.75      ]\n",
      "Accuracy: 0.707 (0.042)\n"
     ]
    }
   ],
   "source": [
    "#6\n",
    "X = uni_num#data\n",
    "y = hash_labels#target\n",
    "\n",
    "kf = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "\n",
    "# create model\n",
    "model = GaussianNB()\n",
    "\n",
    "# evaluate model\n",
    "scores = cross_val_score(model, X, y, scoring='accuracy', cv=kf, n_jobs=-1)\n",
    "print(\"scores:\", scores)\n",
    "\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores: [0.63636364 0.72727273 0.75757576 0.72727273 0.66666667 0.72727273\n",
      " 0.63636364 0.72727273 0.71875    0.75      ]\n",
      "Accuracy: 0.707 (0.042)\n"
     ]
    }
   ],
   "source": [
    "#7\n",
    "X = uni_num_pos#data\n",
    "y = hash_labels#target\n",
    "\n",
    "kf = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "\n",
    "# create model\n",
    "model = GaussianNB()\n",
    "\n",
    "# evaluate model\n",
    "scores = cross_val_score(model, X, y, scoring='accuracy', cv=kf, n_jobs=-1)\n",
    "print(\"scores:\", scores)\n",
    "\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores: [0.75757576 0.72727273 0.66666667 0.72727273 0.75757576 0.72727273\n",
      " 0.75757576 0.72727273 0.78125    0.6875    ]\n",
      "Accuracy: 0.732 (0.033)\n"
     ]
    }
   ],
   "source": [
    "#8\n",
    "X = bi_pos_new#data\n",
    "y = hash_labels#target\n",
    "\n",
    "kf = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "\n",
    "# create model\n",
    "model = GaussianNB()\n",
    "\n",
    "# evaluate model\n",
    "scores = cross_val_score(model, X, y, scoring='accuracy', cv=kf, n_jobs=-1)\n",
    "print(\"scores:\", scores)\n",
    "\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores: [0.75757576 0.72727273 0.66666667 0.72727273 0.75757576 0.72727273\n",
      " 0.75757576 0.72727273 0.78125    0.6875    ]\n",
      "Accuracy: 0.732 (0.033)\n"
     ]
    }
   ],
   "source": [
    "#9\n",
    "X = bi_num#data\n",
    "y = hash_labels#target\n",
    "\n",
    "kf = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "\n",
    "# create model\n",
    "model = GaussianNB()\n",
    "\n",
    "# evaluate model\n",
    "scores = cross_val_score(model, X, y, scoring='accuracy', cv=kf, n_jobs=-1)\n",
    "print(\"scores:\", scores)\n",
    "\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores: [0.75757576 0.72727273 0.66666667 0.72727273 0.75757576 0.72727273\n",
      " 0.75757576 0.72727273 0.78125    0.6875    ]\n",
      "Accuracy: 0.732 (0.033)\n"
     ]
    }
   ],
   "source": [
    "#10\n",
    "X = bi_num_pos#data\n",
    "y = hash_labels#target\n",
    "\n",
    "kf = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "\n",
    "# create model\n",
    "model = GaussianNB()\n",
    "\n",
    "# evaluate model\n",
    "scores = cross_val_score(model, X, y, scoring='accuracy', cv=kf, n_jobs=-1)\n",
    "print(\"scores:\", scores)\n",
    "\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores: [0.63636364 0.72727273 0.78787879 0.72727273 0.66666667 0.72727273\n",
      " 0.66666667 0.72727273 0.75       0.75      ]\n",
      "Accuracy: 0.717 (0.044)\n"
     ]
    }
   ],
   "source": [
    "#11\n",
    "X = tfidf_pos_new#data\n",
    "y = hash_labels#target\n",
    "\n",
    "kf = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "\n",
    "# create model\n",
    "model = GaussianNB()\n",
    "\n",
    "# evaluate model\n",
    "scores = cross_val_score(model, X, y, scoring='accuracy', cv=kf, n_jobs=-1)\n",
    "print(\"scores:\", scores)\n",
    "\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores: [0.63636364 0.72727273 0.78787879 0.72727273 0.66666667 0.72727273\n",
      " 0.66666667 0.72727273 0.75       0.75      ]\n",
      "Accuracy: 0.717 (0.044)\n"
     ]
    }
   ],
   "source": [
    "#12\n",
    "X = tfidf_num#data\n",
    "y = hash_labels#target\n",
    "\n",
    "kf = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "\n",
    "# create model\n",
    "model = GaussianNB()\n",
    "\n",
    "# evaluate model\n",
    "scores = cross_val_score(model, X, y, scoring='accuracy', cv=kf, n_jobs=-1)\n",
    "print(\"scores:\", scores)\n",
    "\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores: [0.63636364 0.72727273 0.78787879 0.72727273 0.66666667 0.72727273\n",
      " 0.66666667 0.72727273 0.75       0.75      ]\n",
      "Accuracy: 0.717 (0.044)\n"
     ]
    }
   ],
   "source": [
    "#13\n",
    "X = tfidf_num_pos#data\n",
    "y = hash_labels#target\n",
    "\n",
    "kf = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "\n",
    "# create model\n",
    "model = GaussianNB()\n",
    "\n",
    "# evaluate model\n",
    "scores = cross_val_score(model, X, y, scoring='accuracy', cv=kf, n_jobs=-1)\n",
    "print(\"scores:\", scores)\n",
    "\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores: [0.48484848 0.21212121 0.24242424 0.24242424 0.33333333 0.24242424\n",
      " 0.24242424 0.3030303  0.34375    0.34375   ]\n",
      "Accuracy: 0.299 (0.078)\n"
     ]
    }
   ],
   "source": [
    "#14 WTF\n",
    "X = wordvec_pos#data\n",
    "y = hash_labels#target\n",
    "\n",
    "kf = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "\n",
    "# create model\n",
    "model = GaussianNB()\n",
    "\n",
    "# evaluate model\n",
    "scores = cross_val_score(model, X, y, scoring='accuracy', cv=kf, n_jobs=-1)\n",
    "print(\"scores:\", scores)\n",
    "\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores: [0.48484848 0.21212121 0.24242424 0.24242424 0.33333333 0.24242424\n",
      " 0.24242424 0.3030303  0.34375    0.34375   ]\n",
      "Accuracy: 0.299 (0.078)\n"
     ]
    }
   ],
   "source": [
    "#15 WTF\n",
    "X = wordvec_num#data\n",
    "y = hash_labels#target\n",
    "\n",
    "kf = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "\n",
    "# create model\n",
    "model = GaussianNB()\n",
    "\n",
    "# evaluate model\n",
    "scores = cross_val_score(model, X, y, scoring='accuracy', cv=kf, n_jobs=-1)\n",
    "print(\"scores:\", scores)\n",
    "\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores: [0.48484848 0.21212121 0.24242424 0.24242424 0.33333333 0.24242424\n",
      " 0.24242424 0.3030303  0.34375    0.34375   ]\n",
      "Accuracy: 0.299 (0.078)\n"
     ]
    }
   ],
   "source": [
    "#16\n",
    "X = wordvec_num_pos#data\n",
    "y = hash_labels#target\n",
    "\n",
    "kf = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "\n",
    "# create model\n",
    "model = GaussianNB()\n",
    "# evaluate model\n",
    "scores = cross_val_score(model, X, y, scoring='accuracy', cv=kf, n_jobs=-1)\n",
    "print(\"scores:\", scores)\n",
    "\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores: [0.81818182 0.78787879 0.87878788 0.84848485 0.78787879 0.63636364\n",
      " 0.78787879 0.90909091 0.6875     0.8125    ]\n",
      "Accuracy: 0.795 (0.078)\n"
     ]
    }
   ],
   "source": [
    "#17\n",
    "X = docvec_pos#data\n",
    "y = hash_labels#target\n",
    "\n",
    "kf = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "\n",
    "# create model\n",
    "model = GaussianNB()\n",
    "\n",
    "# evaluate model\n",
    "scores = cross_val_score(model, X, y, scoring='accuracy', cv=kf, n_jobs=-1)\n",
    "print(\"scores:\", scores)\n",
    "\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores: [0.75757576 0.78787879 0.87878788 0.84848485 0.81818182 0.63636364\n",
      " 0.81818182 0.90909091 0.75       0.8125    ]\n",
      "Accuracy: 0.802 (0.072)\n"
     ]
    }
   ],
   "source": [
    "#18\n",
    "X = docvec_num#data\n",
    "y = hash_labels#target\n",
    "\n",
    "kf = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "\n",
    "# create model\n",
    "model = GaussianNB()\n",
    "\n",
    "# evaluate model\n",
    "scores = cross_val_score(model, X, y, scoring='accuracy', cv=kf, n_jobs=-1)\n",
    "print(\"scores:\", scores)\n",
    "\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores: [0.75757576 0.78787879 0.87878788 0.84848485 0.81818182 0.66666667\n",
      " 0.81818182 0.90909091 0.71875    0.8125    ]\n",
      "Accuracy: 0.802 (0.069)\n"
     ]
    }
   ],
   "source": [
    "#19\n",
    "X = docvec_num_pos#data\n",
    "y = hash_labels#target\n",
    "\n",
    "kf = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "\n",
    "# create model\n",
    "model = GaussianNB()\n",
    "\n",
    "# evaluate model\n",
    "scores = cross_val_score(model, X, y, scoring='accuracy', cv=kf, n_jobs=-1)\n",
    "print(\"scores:\", scores)\n",
    "\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores: [0.57575758 0.72727273 0.78787879 0.75757576 0.6969697  0.81818182\n",
      " 0.75757576 0.78787879 0.625      0.6875    ]\n",
      "Accuracy: 0.722 (0.073)\n"
     ]
    }
   ],
   "source": [
    "#20\n",
    "X = pos_num#data\n",
    "y = hash_labels#target\n",
    "\n",
    "kf = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "\n",
    "# create model\n",
    "model = GaussianNB()\n",
    "\n",
    "# evaluate model\n",
    "scores = cross_val_score(model, X, y, scoring='accuracy', cv=kf, n_jobs=-1)\n",
    "print(\"scores:\", scores)\n",
    "\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores: [0.81818182 0.81818182 0.84848485 0.81818182 0.78787879 0.81818182\n",
      " 0.75757576 0.75757576 0.65625    0.71875   ]\n",
      "Accuracy: 0.780 (0.055)\n"
     ]
    }
   ],
   "source": [
    "#21\n",
    "X = all_features#data\n",
    "y = hash_labels#target\n",
    "\n",
    "kf = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "\n",
    "# create model\n",
    "model = GaussianNB()\n",
    "\n",
    "# evaluate model\n",
    "scores = cross_val_score(model, X, y, scoring='accuracy', cv=kf, n_jobs=-1)\n",
    "print(\"scores:\", scores)\n",
    "\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores: [0.63636364 0.72727273 0.75757576 0.72727273 0.66666667 0.72727273\n",
      " 0.63636364 0.72727273 0.71875    0.75      ]\n",
      "Accuracy: 0.707 (0.042)\n"
     ]
    }
   ],
   "source": [
    "#21\n",
    "X = emot_uni#data\n",
    "y = hash_labels#target\n",
    "\n",
    "kf = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "\n",
    "# create model\n",
    "model = GaussianNB()\n",
    "\n",
    "# evaluate model\n",
    "scores = cross_val_score(model, X, y, scoring='accuracy', cv=kf, n_jobs=-1)\n",
    "print(\"scores:\", scores)\n",
    "\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores: [0.75757576 0.72727273 0.66666667 0.72727273 0.75757576 0.72727273\n",
      " 0.75757576 0.72727273 0.78125    0.6875    ]\n",
      "Accuracy: 0.732 (0.033)\n"
     ]
    }
   ],
   "source": [
    "#21\n",
    "X = emot_bi#data\n",
    "y = hash_labels#target\n",
    "\n",
    "kf = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "\n",
    "# create model\n",
    "model = GaussianNB()\n",
    "\n",
    "# evaluate model\n",
    "scores = cross_val_score(model, X, y, scoring='accuracy', cv=kf, n_jobs=-1)\n",
    "print(\"scores:\", scores)\n",
    "\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores: [0.63636364 0.72727273 0.78787879 0.72727273 0.66666667 0.72727273\n",
      " 0.66666667 0.72727273 0.75       0.75      ]\n",
      "Accuracy: 0.717 (0.044)\n"
     ]
    }
   ],
   "source": [
    "#21\n",
    "X = emot_tfidf#data\n",
    "y = hash_labels#target\n",
    "\n",
    "kf = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "\n",
    "# create model\n",
    "model = GaussianNB()\n",
    "\n",
    "# evaluate model\n",
    "scores = cross_val_score(model, X, y, scoring='accuracy', cv=kf, n_jobs=-1)\n",
    "print(\"scores:\", scores)\n",
    "\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores: [0.48484848 0.21212121 0.24242424 0.24242424 0.33333333 0.24242424\n",
      " 0.24242424 0.3030303  0.34375    0.34375   ]\n",
      "Accuracy: 0.299 (0.078)\n"
     ]
    }
   ],
   "source": [
    "#21 WTF\n",
    "X = emot_wordvec#data\n",
    "y = hash_labels#target\n",
    "\n",
    "kf = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "\n",
    "# create model\n",
    "model = GaussianNB()\n",
    "\n",
    "# evaluate model\n",
    "scores = cross_val_score(model, X, y, scoring='accuracy', cv=kf, n_jobs=-1)\n",
    "print(\"scores:\", scores)\n",
    "\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores: [0.75757576 0.78787879 0.87878788 0.87878788 0.75757576 0.63636364\n",
      " 0.75757576 0.93939394 0.75       0.78125   ]\n",
      "Accuracy: 0.793 (0.082)\n"
     ]
    }
   ],
   "source": [
    "#21\n",
    "X = emot_docvec#data\n",
    "y = hash_labels#target\n",
    "\n",
    "kf = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "\n",
    "# create model\n",
    "model = GaussianNB()\n",
    "\n",
    "# evaluate model\n",
    "scores = cross_val_score(model, X, y, scoring='accuracy', cv=kf, n_jobs=-1)\n",
    "print(\"scores:\", scores)\n",
    "\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
